# Исследование моделей и инфраструктуры

## 1. Сравнение локальных и облачных LLM-модели
| Критерий                               | Локальные модели                                                                                                                                                                                                           | Облачные модели (OpenAI / YandexGPT)                                                                                                                                                                                      |
|----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Качество ответов**                   | - Могут уступать в сложных задачах (глубокий анализ, многошаговые рассуждения).<br> - Подходят для большинства повседневных сценариев.                                                                                     | - Лучше в сложных задачах, требующих глубокого анализа и мультиязычной поддержки.                                                                                                                                         |
| **Скорость работы**                    | - Зависит от мощности локального оборудования.<br>- На слабом железе даже компактные модели (например, T‑Lite 7B) могут работать медленно.<br>- Возможна оптимизация: квантизация (GGUF), настройка под конкретное железо. | - Стабильная скорость благодаря инфраструктуре провайдера.<br>- Возможны задержки из‑за сетевых факторов и нагрузки на серверы.                                                                                           |
| **Стоимость владения и использования** | - Разовые затраты: оборудование (серверы, GPU), настройка инфраструктуры.<br>- Текущие расходы: обслуживание, охлаждение, электроэнергия, зарплаты специалистов.<br>- Экономически выгоднее при интенсивной нагрузке.      | - Оплата за токен/запрос.<br>- В Yandex Cloud стоимость зависит от типа модели и режима (синхронный/асинхронный).<br>- Выгодно для небольших проектов и нерегулярного использования; при высокой нагрузке расходы растут. |
| **Удобство и простота развёртывания**  | - Требует технической экспертизы: выбор и настройка оборудования, установка ПО (Hugging Face Transformers, llama.cpp, Ollama).<br>- Время на оптимизацию параметров и интеграцию.                                          | - Готовые API с документацией и поддержкой.<br>- Простая интеграция (например, через OpenAI SDK).<br>- Быстрое внедрение без забот об инфраструктуре.                                                                     |

## 2. Сравните локальных и облачных эмбеддингов

| Критерий                               | Локальные Sentence-Transformers                                                                                                                                                                                                                                                                                        | Облачные OpenAI Embeddings                                                                                                                                                                                                                                                              |
|:---------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Скорость создания индекса**          | - Высокая, особенно на GPU. Скорость определяется производительностью локального железа и отсутствием сетевых задержек.                                                                                                                                                                                                | - Зависит от API и сети. На скорость влияют задержки сети и текущая нагрузка API, что приводит к высокой дисперсии времени отклика.                                                                                                                                                     |
| **Качество поиска**                    | - Конкурирует или превосходит, зависит от модели. Качество можно повысить тонкой настройкой под домен.                                                                                                                                                                                                                 | - Высокое, но не всегда лучшее. Нет возможности настроить под задачу                                                                                                                                                                                                                    |
| **Стоимость владения и использования** | - Высокие начальные/фиксированные затраты, низкие операционные. Требуются затраты на инфраструктуру (GPU/CPU, память), настройку и обслуживание. После развертывания стоимость обработки миллионов токенов стремится сильно снижается. Идеально для больших объемов, строгих требований к конфиденциальности и данным. | - Легкая настройка, высокие операционные расходы. Отсутствуют затраты на инфраструктуру и обслуживание, оплата по мере использования. Стоимость растет линейно с масштабом и может стать значительной при больших объемах индексации и запросов. Существует риск привязки к поставщику. |

## 3. Сравните векторные базы ChromaDB и FAISS  

| Критерий                            | ChromaDB                                                                                                                                                                       | FAISS                                                                                                                                                                                                                   |
|:------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Скорость поиска и индексации**    | Умеренная скорость. Запросы занимают порядка 10-100 мс на 1M векторов. Подходит для средних нагрузок.                                                                          | Максимальная производительность. Оптимизированная библиотека с поддержкой GPU (ускорение до 5-10x). Латентность <1 мс. Поддерживает миллиарды векторов.                                                                 |
| **Сложность внедрения и поддержки** | Низкая. Готовое решение с простым API (Python/JavaScript). Встроенное управление данными (CRUD, персистентность).                                                              | Высокая. Библиотека (C++/Python), а не готовая СУБД. Требует самостоятельной реализации персистентности, API, мониторинга и интеграции с хранилищем метаданных.                                                         |
| **Удобство в работе**               | Высокое. Встроенная работа с метаданными и их фильтрация, что критично для RAG. Быстрое прототипирование.                                                                      | Низкое (но высокая гибкость). Предоставляет базовые строительные блоки для поиска. Отсутствуют встроенные функции работы с метаданными, требуется внешняя система.                                                      |
| **Стоимость владения**              | Низкая начальная стоимость. Открытый исходный код, работает на стандартной CPU-инфраструктуре. Затраты в основном на разработку (минимальны) и эксплуатацию виртуальных машин. | Высокая совокупная стоимость владения (TCO). Бесплатная библиотека, но требуются значительные инженерные ресурсы для разработки и поддержки полноценной системы. Для максимальной скорости необходимы GPU.              |

## 4. Конфигурация серверов

Сервер: 8–16 vCPU, 32 ГБ RAM, 100 ГБ SSD, NVIDIA T4.
Векторная БД: Qdrant single-node (или Pinecone starter pod).
Хранилище векторов: ~6 ГБ (500K векторов 768d) + резерв для роста.
